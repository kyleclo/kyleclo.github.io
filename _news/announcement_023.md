---
layout: post
date: 2025-03-13 00:00:01-0800
inline: true
---

We released our largest and best model yet! **OLMo 2 32B** is trained using the same recipe from [2 OLMo 2 Furious](https://arxiv.org/abs/2501.00656), comparable base model performance to some of the best open-weight models like Qwen and Gemma. After instruction tuning, it's the best fully open model to reach GPT 3.5/4o mini performance.  Our [blog post](https://allenai.org/blog/olmo2-32b) says more. As always, download the model weights, data, and everything on [HuggingFace](https://huggingface.co/collections/allenai/olmo-2-674117b93ab84e98afc72edc)!
